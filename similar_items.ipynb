{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "City5_WJEfye"
   },
   "source": [
    "# Algorithms for Data Science"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ySZT0ubAEjJ3"
   },
   "source": [
    "## Finding Similar Items"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "mGqRZ-W1EoJQ"
   },
   "source": [
    "The objective of this lab is to implement the Min-Hashing and Locality Sensitive Hashing. This lab needs Python and Jupyter, along with the NumPy package.\n",
    "\n",
    "1. We first load the required libraries and the files containing the documents."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 72
    },
    "colab_type": "code",
    "id": "onDbJw2yEfXa",
    "outputId": "db289d42-dd72-4488-e6f8-55940a404660"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of documents: 497\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import numpy as np\n",
    "import urllib.request\n",
    "import re\n",
    "import string\n",
    "import random\n",
    "\n",
    "file_location = 'https://www.lri.fr/~maniu/tweets.txt' #you can change this to a local file on your computer\n",
    "\n",
    "#keeping document in memory\n",
    "infile = urllib.request.urlopen(file_location)\n",
    "docs = []\n",
    "\n",
    "for line in infile: \n",
    "  docs.append(str(line.strip()).lower())\n",
    "print(\"Number of documents: %d\"%len(docs))\n",
    "#print(docs)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "dzCsuFbiGmI7"
   },
   "source": [
    "2. We transform the document into $k$-shingles, and we hash them to their integer values. We compute the Jaccard similarity between two documents given as sets of shingle ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 52
    },
    "colab_type": "code",
    "id": "EoyEXIR7GzeR",
    "outputId": "b62e1f90-476f-4faf-c9ac-65e043bbd2d9"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique shingles: 19532\n",
      "Total shingles: 28150\n"
     ]
    }
   ],
   "source": [
    "k = 5 #k for shingles\n",
    "\n",
    "shingle_id = {}\n",
    "id_shingle = []\n",
    "m = [] # matrix of the document (hash table)\n",
    "ids = 0 # the order of the unique shingle_id\n",
    "\n",
    "total_shingles = 0\n",
    "\n",
    "for d in docs:\n",
    "  #removing whitespace\n",
    "  d_new = ''.join(c for c in d if c.isalnum())\n",
    "  char_shing = [d_new[i:i+k] for i in range(len(d_new)-k+1)]\n",
    "  total_shingles += len(char_shing)\n",
    "  sid = set()\n",
    "  for sh in char_shing:\n",
    "    if sh not in shingle_id:\n",
    "      shingle_id[sh]=ids\n",
    "      id_shingle.append(sh)\n",
    "      ids=ids+1\n",
    "    sid.add(shingle_id[sh])\n",
    "  m.append(sid)\n",
    "\n",
    "print (\"Unique shingles: %d\"%len(id_shingle))\n",
    "print (\"Total shingles: %d\"%total_shingles)\n",
    "  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497\n"
     ]
    }
   ],
   "source": [
    "print(len(m))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "2vciVEmjUiIU",
    "outputId": "057a20f3-f743-4633-f1ec-cffd7ecb806d"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.043859649122807015\n"
     ]
    }
   ],
   "source": [
    "def jaccard_similarity(doc1, doc2):\n",
    "  if len(doc1)==0 or len(doc2)==0:\n",
    "    return 0.0\n",
    "  else:\n",
    "    inter = doc1.intersection(doc2)\n",
    "    union = doc1.union(doc2)\n",
    "    return float(len(inter))/float(len(union))\n",
    "\n",
    "#example\n",
    "\n",
    "print(jaccard_similarity(m[0],m[1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "yovaXpHCG0FL"
   },
   "source": [
    "3. We implement the method for min-hashing given a permutation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 34
    },
    "colab_type": "code",
    "id": "fpd3J3HsHW6m",
    "outputId": "74affc79-b1f4-4110-e4e8-4239bc2f8a88"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "497\n",
      "19532\n"
     ]
    }
   ],
   "source": [
    "def min_hash(doc,perm):\n",
    "  for d in perm:\n",
    "    if d in doc: \n",
    "          return d  # return the first appear signature\n",
    "    \n",
    "perm = list(range(len(id_shingle)))\n",
    "random.shuffle(perm)\n",
    "#print(perm)\n",
    "min_hash(m[0],perm)\n",
    "print(len(m))\n",
    "print(len(id_shingle))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 120,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "min_hash(m[0],perm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "hJD2piyyHXXe"
   },
   "source": [
    "4. Implement the full Min-Hashing signature matrix for a given number $n$ of permutations. Implement the similarity estimation based on Min-Hashing (i.e., the number of permutation on which two documents agree)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "96nNQIfgWLto"
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "def min_hash_sim(lst1,lst2):\n",
    "    assert(len(lst1)==len(lst2))\n",
    "    agree=0\n",
    "    for i in range(len(lst1)):\n",
    "        if (lst1[i]==lst2[i]):\n",
    "            agree=agree+1\n",
    "    return agree/len(lst1)\n",
    "\n",
    "# generate several permutations\n",
    "n=100\n",
    "p=[]\n",
    "for _ in range(n):\n",
    "    perm = list(range(len(id_shingle)))\n",
    "    random.shuffle(perm)\n",
    "    p.append(perm)\n",
    "sig=[]\n",
    "\n",
    "for doc in m:\n",
    "    h=[] # documents\n",
    "    for per in p:\n",
    "        hval=min_hash(doc,per)\n",
    "        h.append(hval)\n",
    "    sig.append(h) # signature matrix\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "wpS0J_z4WN0T"
   },
   "source": [
    "5. __TASK__ Implement Locality-Sensitive Hashing, given $b$ bands of $r$ rows such that $br=n$. Compute the similarity threshold needed using the formula in the lecture $t=(1/b)^{1/r}$. Assume that signatures in the same band are similar only if the are the same (i.e., they agree on all columns). Check for similarity all documents that agree in at least one band, and compare with the true jaccard similarity."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Situation 1: r=2 b=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "h08gagG8YUkh"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "50\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "#1. define the similarity threshold s, find b and r\n",
    "#b*r=100\n",
    "r=2\n",
    "b=int(n/r)\n",
    "s=(1/b)**(1/r)\n",
    "\n",
    "chunks = [[s[x:x+r] for x in range(0, b*r, r)] for s in sig]\n",
    "#2. each document is an array of length n , you have to devide it into b bands of r values\n",
    "bands= [{}for i in range (b)]\n",
    "for i in range(len(bands)):\n",
    "    for doc_id,chunk in enumerate(chunks):\n",
    "        \n",
    "        key ='_'.join(map(str, chunk[i]))\n",
    "        if key not in bands[i]:\n",
    "            bands[i][key]=[]  # add the unique hash key \n",
    "        bands[i][key].append(doc_id) \n",
    "#print (bands[0])           \n",
    "print (len([band for band in bands if len([value for value in band.values() if len(value)>1])]))\n",
    "#3. have a dictionary per band: keys are the hashes of the partial signatures, values are list of document ids\n",
    "\n",
    "#4. for each document, divide it into b slices ( b slices of r value), one possible has [1,5,4,2]\n",
    "#b=2,r=2 hash1=\"1_5\" hash2=\"4_2\";add the document id to the list (in the dict) corresponding to the hash\n",
    "#5. loop over the values in the dict; retrive list in each key; do pairwise comparaison; reject sim<s\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Find the similarity pair of the documents compare jaccard similarity with threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_docs = {}\n",
    "for band in bands: \n",
    "    for key, value in band.items():\n",
    "        if len(value)>1:\n",
    "            for doc1,doc2,sim in [(x,y,jaccard_similarity(m[x], m[y])) for i,x in enumerate(value) for j,y in enumerate(value) if i != j]:\n",
    "                if sim>s and f'{doc1}/{doc2}' not in sim_docs and f'{doc2}/{doc1}' not in sim_docs:\n",
    "                    sim_docs[f'{doc1}/{doc2}'] = sim"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Print the similar document pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "182\n",
      "1/237\n",
      "10/12\n",
      "45/283\n",
      "46/284\n",
      "52/53\n",
      "52/288\n",
      "53/288\n",
      "124/131\n",
      "169/408\n",
      "183/423\n",
      "61/303\n",
      "109/110\n",
      "109/352\n",
      "110/352\n",
      "124/363\n",
      "131/363\n",
      "129/370\n",
      "475/477\n",
      "78/319\n",
      "8/62\n",
      "8/303\n",
      "62/303\n",
      "45/47\n",
      "45/281\n",
      "45/284\n",
      "47/281\n",
      "47/284\n",
      "281/284\n",
      "61/63\n",
      "244/245\n",
      "10/411\n",
      "58/290\n",
      "303/304\n",
      "303/305\n",
      "304/305\n",
      "107/348\n",
      "124/125\n",
      "124/128\n",
      "124/129\n",
      "124/362\n",
      "124/365\n",
      "124/368\n",
      "124/371\n",
      "125/128\n",
      "125/129\n",
      "125/362\n",
      "125/363\n",
      "125/365\n",
      "125/368\n",
      "125/371\n",
      "126/128\n",
      "126/129\n",
      "128/129\n",
      "128/362\n",
      "128/363\n",
      "128/365\n",
      "128/368\n",
      "128/371\n",
      "129/362\n",
      "129/363\n",
      "129/365\n",
      "129/368\n",
      "129/371\n",
      "362/363\n",
      "362/365\n",
      "362/368\n",
      "362/371\n",
      "363/365\n",
      "363/368\n",
      "363/371\n",
      "365/368\n",
      "365/371\n",
      "368/371\n",
      "51/53\n",
      "51/288\n",
      "124/361\n",
      "124/370\n",
      "125/361\n",
      "125/370\n",
      "361/363\n",
      "363/370\n",
      "368/370\n",
      "128/372\n",
      "406/409\n",
      "108/109\n",
      "108/110\n",
      "108/352\n",
      "124/132\n",
      "125/132\n",
      "129/132\n",
      "132/362\n",
      "132/363\n",
      "362/370\n",
      "71/311\n",
      "84/311\n",
      "310/311\n",
      "126/372\n",
      "128/134\n",
      "152/391\n",
      "19/252\n",
      "86/328\n",
      "129/130\n",
      "129/135\n",
      "129/364\n",
      "130/135\n",
      "130/370\n",
      "135/370\n",
      "125/372\n",
      "55/294\n",
      "40/278\n",
      "61/62\n",
      "61/300\n",
      "62/63\n",
      "62/300\n",
      "63/300\n",
      "109/111\n",
      "111/352\n",
      "125/131\n",
      "131/371\n",
      "365/366\n",
      "109/351\n",
      "110/111\n",
      "111/351\n",
      "351/352\n",
      "127/367\n",
      "188/190\n",
      "283/284\n",
      "175/421\n",
      "108/111\n",
      "108/351\n",
      "124/366\n",
      "125/366\n",
      "129/361\n",
      "129/366\n",
      "361/362\n",
      "362/366\n",
      "363/366\n",
      "366/368\n",
      "366/371\n",
      "209/468\n",
      "124/135\n",
      "124/369\n",
      "125/135\n",
      "125/369\n",
      "129/369\n",
      "135/363\n",
      "135/365\n",
      "135/366\n",
      "135/368\n",
      "135/371\n",
      "363/369\n",
      "368/369\n",
      "126/127\n",
      "127/128\n",
      "127/372\n",
      "393/398\n",
      "396/398\n",
      "44/45\n",
      "44/283\n",
      "62/304\n",
      "62/305\n",
      "63/303\n",
      "141/391\n",
      "61/301\n",
      "63/301\n",
      "252/259\n",
      "46/47\n",
      "353/354\n",
      "56/291\n",
      "55/58\n",
      "57/58\n",
      "57/290\n",
      "58/295\n",
      "124/372\n",
      "363/372\n",
      "136/362\n",
      "154/391\n",
      "301/304\n",
      "57/294\n",
      "57/291\n",
      "45/46\n",
      "46/283\n"
     ]
    }
   ],
   "source": [
    "print(len(sim_docs.keys()))\n",
    "for key in sim_docs.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we choose r=2 we have 182 pair that is similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Situation2: r=5 b=20"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "8\n"
     ]
    }
   ],
   "source": [
    "# YOUR CODE HERE\n",
    "\n",
    "#1. define the similarity threshold s, find b and r\n",
    "#b*r=100\n",
    "r=5\n",
    "b=int(n/r)\n",
    "s=(1/b)**(1/r)\n",
    "\n",
    "chunks = [[s[x:x+r] for x in range(0, b*r, r)] for s in sig]\n",
    "\n",
    "bands= [{}for i in range (b)]\n",
    "for i in range(len(bands)):\n",
    "    for doc_id,chunk in enumerate(chunks):\n",
    "        \n",
    "        key ='_'.join(map(str, chunk[i]))\n",
    "        if key not in bands[i]:\n",
    "            bands[i][key]=[]  # add the unique hash key \n",
    "        bands[i][key].append(doc_id) \n",
    "#print (bands[0])           \n",
    "print (len([band for band in bands if len([value for value in band.values() if len(value)>1])]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [],
   "source": [
    "sim_docs = {}\n",
    "for band in bands: \n",
    "    for key, value in band.items():\n",
    "        if len(value)>1:\n",
    "            for doc1,doc2,sim in [(x,y,jaccard_similarity(m[x], m[y])) for i,x in enumerate(value) for j,y in enumerate(value) if i != j]:\n",
    "                if sim>s and f'{doc1}/{doc2}' not in sim_docs and f'{doc2}/{doc1}' not in sim_docs:\n",
    "                    sim_docs[f'{doc1}/{doc2}'] = sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "124/363\n",
      "244/245\n",
      "110/352\n"
     ]
    }
   ],
   "source": [
    "for key in sim_docs.keys():\n",
    "    print(key)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When we choose a bigger r we have three pair that is similar"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To choose an ideal r, we need to plot the s curve and see the surface of the false postive and false negatives. The idea is to minimize them both.  "
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "m2_ds_algods_lab1_similar.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  },
  "vscode": {
   "interpreter": {
    "hash": "aee8b7b246df8f9039afb4144a1f6fd8d2ca17a180786b69acc140d282b71a49"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
